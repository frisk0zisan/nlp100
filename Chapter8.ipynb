{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRPzAgl1U+GSWrWg3yIOuG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frisk0zisan/nlp100/blob/main/Chapter8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_feZb3i1I5qz"
      },
      "source": [
        "# 8章：ニューラルネット\n",
        "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ。  \n",
        "->今回はPytorchを使う。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbLnQEMeK-eC"
      },
      "source": [
        "## 70. 単語ベクトルの和による特徴量Permalink\n",
        "\n",
        "問題50で構築した学習データ，検証データ，評価データを行列・ベクトルに変換したい．例えば，学習データについて，すべての事例$x_i$の特徴ベクトル$\\boldsymbol{x}_i$を並べた行列$X$と正解ラベルを並べた行列（ベクトル）$Y$を作成したい．\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix} \n",
        "  \\boldsymbol{x}_1 \\\\ \n",
        "  \\boldsymbol{x}_2 \\\\ \n",
        "  \\dots \\\\ \n",
        "  \\boldsymbol{x}_n \\\\ \n",
        "\\end{pmatrix} \\in \\mathbb{R}^{n \\times d},\n",
        "Y = \\begin{pmatrix} \n",
        "  y_1 \\\\ \n",
        "  y_2 \\\\ \n",
        "  \\dots \\\\ \n",
        "  y_n \\\\ \n",
        "\\end{pmatrix} \\in \\mathbb{N}^{n}\n",
        "$$\n",
        "\n",
        "\n",
        " ここで，$n$は学習データの事例数であり，$\\boldsymbol x_i \\in \\mathbb{R}^d$と$y_i \\in \\mathbb N$はそれぞれ，$i \\in \\{1, \\dots, n\\}$番目の事例の特徴量ベクトルと正解ラベルを表す．\n",
        " なお，今回は「ビジネス」「科学技術」「エンターテイメント」「健康」の4カテゴリ分類である．$\\mathbb N_{<4}$で$4$未満の自然数（$0$を含む）を表すことにすれば，任意の事例の正解ラベル$y_i$は$y_i \\in \\mathbb N_{<4}$で表現できる．\n",
        " 以降では，ラベルの種類数を$L$で表す（今回の分類タスクでは$L=4$である）．\n",
        "\n",
        " $i$番目の事例の特徴ベクトル$\\boldsymbol x_i$は，次式で求める．\n",
        "\n",
        " $$\\boldsymbol x_i = \\frac{1}{T_i} \\sum_{t=1}^{T_i} \\mathrm{emb}(w_{i,t})$$\n",
        "\n",
        " ここで，$i$番目の事例は$T_i$個の（記事見出しの）単語列$(w_{i,1}, w_{i,2}, \\dots, w_{i,T_i})$から構成され，$\\mathrm{emb}(w) \\in \\mathbb{R}^d$は単語$w$に対応する単語ベクトル（次元数は$d$）である．  \n",
        " すなわち，$i$番目の事例の記事見出しを，その見出しに含まれる単語のベクトルの平均で表現したものが$\\boldsymbol x_i$である．今回は単語ベクトルとして，問題60でダウンロードしたものを用いればよい．$300$次元の単語ベクトルを用いたので，$d=300$である．  \n",
        " $i$番目の事例のラベル$y_i$は，次のように定義する．\n",
        "\n",
        "$$\n",
        "y_i = \\begin{cases}\n",
        "0 & (\\mbox{記事}\\boldsymbol x_i\\mbox{が「ビジネス」カテゴリの場合}) \\\\\n",
        "1 & (\\mbox{記事}\\boldsymbol x_i\\mbox{が「科学技術」カテゴリの場合}) \\\\\n",
        "2 & (\\mbox{記事}\\boldsymbol x_i\\mbox{が「エンターテイメント」カテゴリの場合}) \\\\\n",
        "3 & (\\mbox{記事}\\boldsymbol x_i\\mbox{が「健康」カテゴリの場合}) \\\\\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "なお，カテゴリ名とラベルの番号が一対一で対応付いていれば，上式の通りの対応付けでなくてもよい．\n",
        "\n",
        "以上の仕様に基づき，以下の行列・ベクトルを作成し，ファイルに保存せよ．\n",
        "\n",
        " + 学習データの特徴量行列: $X_{\\rm train} \\in \\mathbb{R}^{N_t \\times d}$\n",
        " + 学習データのラベルベクトル: $Y_{\\rm train} \\in \\mathbb{N}^{N_t}$\n",
        " + 検証データの特徴量行列: $X_{\\rm valid} \\in \\mathbb{R}^{N_v \\times d}$\n",
        " + 検証データのラベルベクトル: $Y_{\\rm valid} \\in \\mathbb{N}^{N_v}$\n",
        " + 評価データの特徴量行列: $X_{\\rm test} \\in \\mathbb{R}^{N_e \\times d}$\n",
        " + 評価データのラベルベクトル: $Y_{\\rm test} \\in \\mathbb{N}^{N_e}$\n",
        "\n",
        "なお，$N_t, N_v, N_e$はそれぞれ，学習データの事例数，検証データの事例数，評価データの事例数である．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzPxkuKGbawt"
      },
      "source": [
        "6章の問50と同様の処理を行う。  \n",
        "データダウンロード後に、データ分割後に保存する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnNu01kRFyty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93880ac7-99d6-4a5e-ab76-79f2bcf371ff"
      },
      "source": [
        "## データのダウンロード\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
        "!unzip NewsAggregatorDataset.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-31 02:34:36--  https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29224203 (28M) [application/x-httpd-php]\n",
            "Saving to: ‘NewsAggregatorDataset.zip’\n",
            "\n",
            "NewsAggregatorDatas 100%[===================>]  27.87M  24.9MB/s    in 1.1s    \n",
            "\n",
            "2021-01-31 02:34:38 (24.9 MB/s) - ‘NewsAggregatorDataset.zip’ saved [29224203/29224203]\n",
            "\n",
            "Archive:  NewsAggregatorDataset.zip\n",
            "  inflating: 2pageSessions.csv       \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._2pageSessions.csv  \n",
            "  inflating: newsCorpora.csv         \n",
            "  inflating: __MACOSX/._newsCorpora.csv  \n",
            "  inflating: readme.txt              \n",
            "  inflating: __MACOSX/._readme.txt   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9mmzPBc1Nf-",
        "outputId": "5bb1723f-c2d5-480b-b9bd-7c4da733add8"
      },
      "source": [
        "!unzip \"NewsAggregatorDataset.zip\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  NewsAggregatorDataset.zip\n",
            "replace 2pageSessions.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/._2pageSessions.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace newsCorpora.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/._newsCorpora.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/._readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIbE0sSrQIsF"
      },
      "source": [
        "# 読込時のエラー回避のためダブルクォーテーションをシングルクォーテーションに置換\n",
        "!sed -e 's/\"/'\\''/g' ./newsCorpora.csv > ./newsCorpora_re.csv"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udMid2TtQWzK"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## データ読み込み\n",
        "df = pd.read_csv('./newsCorpora_re.csv', header=None, sep='\\t', names=['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n",
        "\n",
        "## データ抽出\n",
        "df = df.loc[df['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']),['TITLE', 'CATEGORY']]\n",
        "\n",
        "## データ分割\n",
        "train, valid_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=123, stratify=df['CATEGORY'])\n",
        "valid, test = train_test_split(valid_test, test_size=0.5, shuffle=True, random_state=123, stratify=valid_test['CATEGORY'])\n",
        "\n",
        "## データ保存\n",
        "train.to_csv('./train.txt', sep='\\t', index=False)\n",
        "valid.to_csv('./valid.txt', sep='\\t', index=False)\n",
        "test.to_csv('./test.txt', sep='\\t', index=False )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhvJJ_j2QvwV",
        "outputId": "6bb096a8-aac3-4c3d-f437-07031afd1ab3"
      },
      "source": [
        "## 事例数の確認\n",
        "print(\"カテゴリ:(b = business, t = science and technology, e = entertainment, m = health)\")\n",
        "print('---学習データ---')\n",
        "print(train['CATEGORY'].value_counts())\n",
        "print('---検証データ---')\n",
        "print(valid['CATEGORY'].value_counts())\n",
        "print('---評価データ---')\n",
        "print(test['CATEGORY'].value_counts())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "カテゴリ:(b = business, t = science and technology, e = entertainment, m = health)\n",
            "---学習データ---\n",
            "b    4501\n",
            "e    4235\n",
            "t    1220\n",
            "m     728\n",
            "Name: CATEGORY, dtype: int64\n",
            "---検証データ---\n",
            "b    563\n",
            "e    529\n",
            "t    153\n",
            "m     91\n",
            "Name: CATEGORY, dtype: int64\n",
            "---評価データ---\n",
            "b    563\n",
            "e    530\n",
            "t    152\n",
            "m     91\n",
            "Name: CATEGORY, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbRlAs-VQ2oD"
      },
      "source": [
        "df = pd.concat([train, valid, test], axis=0)\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCIUeZ_Wbps-"
      },
      "source": [
        "7章の問60と同様の処理を行う。以下7章問60  \n",
        ">Google Newsデータセット（約1,000億単語）での[学習済み単語ベクトル](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit)（300万単語・フレーズ，300次元）をダウンロードし，”United States”の単語ベクトルを表示せよ．ただし，”United States”は内部的には”United_States”と表現されていることに注意せよ．\n",
        "\n",
        "学習済み単語ベクトルをダウンロードして、ロードする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWUO132WboD_"
      },
      "source": [
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMXefF3p2eza",
        "outputId": "91fc7c2b-c3ef-46c8-bec2-49450b93066d"
      },
      "source": [
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n\n",
            "--2021-01-31 02:35:18--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.97.22\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.97.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  81.8MB/s    in 20s     \n",
            "\n",
            "2021-01-31 02:35:37 (79.6 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwnzvMkBctC6"
      },
      "source": [
        "Genismを用いて単語ベクトルを読み込む。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc7UAWtKchGy"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUfC_J0sdUlL"
      },
      "source": [
        "読み込んだ後は、ベクトル化したい単語を指定するだけで簡単に単語ベクトルを得ることができる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9YdR3oYc8r7",
        "outputId": "00f5e530-d6e3-49d1-d254-d21348a6fb71"
      },
      "source": [
        "model['Apple'][:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.17480469,  0.0300293 , -0.21679688,  0.15625   , -0.35742188],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "430IG5wYg6vN"
      },
      "source": [
        "word2vecを用いることで単語の類義語や単語間や文章間の類義度を計ることができる。  \n",
        "以下に「Apple」の類義語を示す。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQL8fGIkgsbY",
        "outputId": "aae74529-50ac-4055-b9c2-885d3f334669"
      },
      "source": [
        "model.most_similar('Apple', topn=5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Apple_AAPL', 0.7456985712051392),\n",
              " ('Apple_Nasdaq_AAPL', 0.7300410270690918),\n",
              " ('Apple_NASDAQ_AAPL', 0.7175089716911316),\n",
              " ('Apple_Computer', 0.7145973443984985),\n",
              " ('iPhone', 0.6924266219139099)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxerjDfp6Urr"
      },
      "source": [
        "後にGPUで学習するためPytorchを使用する。  \n",
        "そのため、Tensor型に変換する。\n",
        "### PythorchのTensor型について\n",
        "numpyのndarray型ととても似ている。  \n",
        "Tensor型を使うと嬉しい点\n",
        "- GPUを利用できる\n",
        "- 勾配情報を簡単に求められる\n",
        "\n",
        "以下にTensor型の練習コードを書く\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKcaI5j2gLqE"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jf0v7oozYhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e86ae1-f4dc-4da3-a4f6-5a66542ec025"
      },
      "source": [
        "## GPUを利用できる\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\n",
        "c = torch.zeros([4], device=device)\n",
        "print(c)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0.], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6Cpum9-ZiUg",
        "outputId": "f030bb43-e636-4bbd-8bb8-c0ceb0cda245"
      },
      "source": [
        "## 勾配情報を簡単に求められる\n",
        "x = torch.tensor(5.0, requires_grad=True)\n",
        "y = 10*x + 20\n",
        "y.backward()\n",
        "\n",
        "print(y)\n",
        "print(x)\n",
        "print(x.grad)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(70., grad_fn=<AddBackward0>)\n",
            "tensor(5., requires_grad=True)\n",
            "tensor(10.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSTVYIepcO2f"
      },
      "source": [
        "特徴ベクトルをTensor型で作成する。\n",
        "特徴ベクトルの以下の通り。（再掲）\n",
        "\n",
        " $i$番目の事例の特徴ベクトル$\\boldsymbol x_i$\n",
        "\n",
        " $$\\boldsymbol x_i = \\frac{1}{T_i} \\sum_{t=1}^{T_i} \\mathrm{emb}(w_{i,t})$$\n",
        "\n",
        "$T_i$：単語列の長さ  \n",
        "$(w_{i,1}, w_{i,2}, \\dots, w_{i,T_i})$：単語列  \n",
        "$\\mathrm{emb}(w) \\in \\mathbb{R}^d$：単語ベクトル  \n",
        "$d$：単語$w$に対応する単語ベクトル（次元数）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYqXwQsibq_X"
      },
      "source": [
        "import string\n",
        "\n",
        "def make_w2v(text):\n",
        "  table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "  words = text.translate(table).split()\n",
        "\n",
        "  vec = [model[word] for word in words if word in model]\n",
        "\n",
        "  return torch.tensor((1/len(words))*sum(vec))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4PnlrgzjkWU"
      },
      "source": [
        "## 特徴ベクトル作成\n",
        "X_train = torch.stack([make_w2v(text) for text in train['TITLE']])\n",
        "X_valid = torch.stack([make_w2v(text) for text in valid['TITLE']])\n",
        "X_test = torch.stack([make_w2v(text) for text in test['TITLE']])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPljR50ykytK",
        "outputId": "01790007-d1ae-4108-96e0-9ae783869a96"
      },
      "source": [
        "print(X_train.size())\n",
        "print(X_train[0:5])\n",
        "print(X_valid.size())\n",
        "print(X_valid[0:5])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10684, 300])\n",
            "tensor([[ 0.0837,  0.0056,  0.0068,  ...,  0.0751,  0.0433, -0.0868],\n",
            "        [ 0.0242,  0.0236, -0.0842,  ..., -0.0930, -0.0435, -0.0082],\n",
            "        [ 0.0577, -0.0159, -0.0780,  ..., -0.0421,  0.1229,  0.0876],\n",
            "        [-0.0555,  0.0496,  0.0620,  ..., -0.0136,  0.0390, -0.0206],\n",
            "        [-0.0259,  0.0775, -0.0256,  ..., -0.0364,  0.1126,  0.0063]])\n",
            "torch.Size([1336, 300])\n",
            "tensor([[-0.0264,  0.1098,  0.0382,  ...,  0.0056,  0.0513,  0.1587],\n",
            "        [ 0.0712,  0.1152, -0.0822,  ..., -0.0151,  0.0091,  0.0217],\n",
            "        [-0.0058,  0.0320, -0.0094,  ...,  0.0195,  0.0591,  0.0504],\n",
            "        [-0.0187,  0.0179,  0.1041,  ..., -0.0404,  0.1052, -0.0224],\n",
            "        [ 0.0134,  0.0070,  0.0432,  ...,  0.0462,  0.0857, -0.0158]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiGEJyNEmiQE"
      },
      "source": [
        "次にラベルベクトルを作成する。  \n",
        "以下に$i$番目の事例のラベル$y_i$の定義を示す（再掲）\n",
        "\n",
        "$$\n",
        "y_i = \\begin{cases}\n",
        "0 & (\\mbox{記事}\\boldsymbol x_i\\mbox{が「ビジネス」カテゴリの場合}) \\\\\n",
        "1 & (\\mbox{記事}\\boldsymbol x_i\\mbox{が「科学技術」カテゴリの場合}) \\\\\n",
        "2 & (\\mbox{記事}\\boldsymbol x_i\\mbox{が「エンターテイメント」カテゴリの場合}) \\\\\n",
        "3 & (\\mbox{記事}\\boldsymbol x_i\\mbox{が「健康」カテゴリの場合}) \\\\\n",
        "\\end{cases}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BLdDoyilWOZ"
      },
      "source": [
        "label_dic ={'b':0, 't':1, 'e':2, 'm':3}\n",
        "y_train = torch.tensor([label_dic[label] for label in train['CATEGORY']])\n",
        "y_valid = torch.tensor([label_dic[label] for label in valid['CATEGORY']])\n",
        "y_test =  torch.tensor([label_dic[label] for label in test['CATEGORY']])\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px0E63zCmtw2",
        "outputId": "5f54c5da-81b1-45c5-d0d8-631b59a63e94"
      },
      "source": [
        "print(y_train.size())\n",
        "print(y_train[0:5])\n",
        "print(y_valid.size())\n",
        "print(y_valid[0:5])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10684])\n",
            "tensor([0, 1, 3, 2, 0])\n",
            "torch.Size([1336])\n",
            "tensor([1, 2, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8wwTug3oATK"
      },
      "source": [
        "## 保存\n",
        "torch.save(X_train, 'X_train.pt')\n",
        "torch.save(X_valid, 'X_valid.pt')\n",
        "torch.save(X_test, 'X_test.pt')\n",
        "torch.save(y_train, 'y_train.pt')\n",
        "torch.save(y_valid, 'y_valid.pt')\n",
        "torch.save(y_test, 'y_test.pt')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GCShFBPtZB0"
      },
      "source": [
        "## 71. 単層ニューラルネットワークによる予測\n",
        "問題70で保存した行列を読み込み，学習データについて以下の計算を実行せよ．\n",
        "\n",
        "$$ \n",
        "\\hat{y}_1=softmax(x_1W),\\\\\\hat{Y}=softmax(X_{[1:4]}W)\n",
        "$$\n",
        "\n",
        "\n",
        "ただし，$softmax$はソフトマックス関数，$X_{[1:4]}∈\\mathbb{R}^{4×d}$は特徴ベクトル$x_1$,$x_2$,$x_3$,$x_4$を縦に並べた行列である．\n",
        "\n",
        "$$\n",
        "X_{[1:4]}=\\begin{pmatrix}x_1\\\\x_2\\\\x_3\\\\x_4\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "行列$W \\in \\mathbb{R}^{d \\times L}$は単層ニューラルネットワークの重み行列で，ここではランダムな値で初期化すればよい（問題73以降で学習して求める）．  \n",
        "なお，$\\hat{\\boldsymbol y_1} \\in \\mathbb{R}^L$は未学習の行列$W$で事例$x_1$を分類したときに，各カテゴリに属する確率を表すベクトルである．\n",
        "同様に，$\\hat{Y} \\in \\mathbb{R}^{n \\times L}$は，学習データの事例$x_1, x_2, x_3, x_4$について，各カテゴリに属する確率を行列として表現している．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmA_YWzW-vyv",
        "outputId": "5ee81125-59df-4d63-f199-0aa8934e00bd"
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10684"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdmCbkPtrTZs"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ5eEcEJvZQb"
      },
      "source": [
        "INPUT_FEATURES = 300  # 入力（特徴）の数： 300\n",
        "OUTPUT_NEURONS = 4  # ニューロンの数： 4\n",
        "\n",
        "## torch.nn.Moduleクラスを継承する\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, input_features, output_neurons):\n",
        "    super(Net, self).__init__()\n",
        "    ## 層（layer）を定義\n",
        "    self.layer = nn.Linear(input_features, output_neurons, bias=False) #Linearは「全結合層」を指す\n",
        "    nn.init.normal_(self.layer.weight, 0.0, 1.0) # 正規乱数で重み初期化\n",
        "\n",
        "  ## フォワードパスを定義\n",
        "  def forward(self, input):\n",
        "    output = self.layer(input)\n",
        "    ##　層を重ねる場合は「出力：output」を次の層の「入力：input」に使う。\n",
        "    return output\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iapyb3HpGDVJ",
        "outputId": "b1ab8077-3a8f-4899-d46d-fdc32ce65654"
      },
      "source": [
        "model = Net(INPUT_FEATURES, OUTPUT_NEURONS)\n",
        "print(model)\n",
        "y_hat_1 = torch.softmax(model(X_train[:1]), dim=-1)\n",
        "print(y_hat_1)\n",
        "Y_hat = torch.softmax(model(X_train[:4]), dim=-1)\n",
        "print(Y_hat)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (layer): Linear(in_features=300, out_features=4, bias=False)\n",
            ")\n",
            "tensor([[0.0296, 0.1538, 0.2084, 0.6082]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[0.0296, 0.1538, 0.2084, 0.6082],\n",
            "        [0.0360, 0.1979, 0.5756, 0.1905],\n",
            "        [0.0299, 0.0502, 0.8569, 0.0631],\n",
            "        [0.1817, 0.0737, 0.1164, 0.6282]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2AZ3dWHJqo9"
      },
      "source": [
        "## 72. 損失と勾配の計算Permalink\n",
        "\n",
        "学習データの事例x1\n",
        "と事例集合x1,x2,x3,x4\n",
        "に対して，クロスエントロピー損失と，行列W\n",
        "に対する勾配を計算せよ．なお，ある事例xi\n",
        "に対して損失は次式で計算される．\n",
        "\n",
        "$$l_i=−log[事例x_iがy_iに分類される確率]$$\n",
        "\n",
        "ただし，事例集合に対するクロスエントロピー損失は，その集合に含まれる各事例の損失の平均とする．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SluMr5KpWpY3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}